import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestClassifier
from sklearn.preprocessing import StandardScaler
import joblib
import numpy as np

# üìå –ó–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–Ω—è –¥–∞–Ω–∏—Ö
try:
    data = pd.read_csv("backend/result.csv")
except FileNotFoundError:
    print("‚ùå –ü–æ–º–∏–ª–∫–∞: –§–∞–π–ª `backend/result.csv` –Ω–µ –∑–Ω–∞–π–¥–µ–Ω–æ!")
    exit()

# üìå –í–∏–¥–∞–ª—è—î–º–æ –º–æ–∂–ª–∏–≤—ñ –ø—Ä–æ–±—ñ–ª–∏ —É –Ω–∞–∑–≤–∞—Ö –∫–æ–ª–æ–Ω–æ–∫
data.columns = data.columns.str.strip()

# üìå –ü–µ—Ä–µ–≤—ñ—Ä—è—î–º–æ –Ω–∞—è–≤–Ω—ñ—Å—Ç—å –Ω–µ–æ–±—Ö—ñ–¥–Ω–∏—Ö –∫–æ–ª–æ–Ω–æ–∫
required_columns = ["pm2_5", "co2", "temperature", "humidity", "health_risk"]
for col in required_columns:
    if col not in data.columns:
        print(f"‚ùå –ü–æ–º–∏–ª–∫–∞: –§–∞–π–ª –Ω–µ –º—ñ—Å—Ç–∏—Ç—å –æ–±–æ–≤'—è–∑–∫–æ–≤–æ—ó –∫–æ–ª–æ–Ω–∫–∏ `{col}`!")
        exit()

# üìä –í–∏–≤–æ–¥–∏–º–æ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É –ø–µ—Ä–µ–¥ –Ω–∞–≤—á–∞–Ω–Ω—è–º
print("üìä –ü–µ—Ä—à—ñ 5 —Ä—è–¥–∫—ñ–≤ –¥–∞–Ω–∏—Ö:\n", data.head())
print("üßê –£–Ω—ñ–∫–∞–ª—å–Ω—ñ —Ä—ñ–≤–Ω—ñ —Ä–∏–∑–∏–∫—É:", data["health_risk"].unique())
print("üìä –ö—ñ–ª—å–∫—ñ—Å—Ç—å –∑–Ω–∞—á–µ–Ω—å —Ä–∏–∑–∏–∫—É:\n", data["health_risk"].value_counts())

# üìå –ó–∞–ø–æ–≤–Ω—é—î–º–æ –ø—Ä–æ–ø—É—â–µ–Ω—ñ –∑–Ω–∞—á–µ–Ω–Ω—è —Å–µ—Ä–µ–¥–Ω—ñ–º–∏ –∑–Ω–∞—á–µ–Ω–Ω—è–º–∏
data.fillna(data.mean(), inplace=True)

# üìå –í–∏–∑–Ω–∞—á–∞—î–º–æ X (–≤—Ö—ñ–¥–Ω—ñ –ø–∞—Ä–∞–º–µ—Ç—Ä–∏) —Ç–∞ y (–º—ñ—Ç–∫–∏ —Ä–∏–∑–∏–∫—É)
X = data[["pm2_5", "co2", "temperature", "humidity"]]
y = data["health_risk"]

# üìå –ú–∞—Å—à—Ç–∞–±—É—î–º–æ –¥–∞–Ω—ñ
scaler = StandardScaler()
X_scaled = scaler.fit_transform(X)

# üìå –î–æ–¥–∞—î–º–æ –≤–∏–ø–∞–¥–∫–æ–≤–∏–π —à—É–º —É —Å–µ–Ω—Å–æ—Ä–∏ (—â–æ–± —É–Ω–∏–∫–Ω—É—Ç–∏ –ø–µ—Ä–µ–æ–±—É—á–µ–Ω–Ω—è)
noise = np.random.normal(0, 0.5, X_scaled.shape)  
X_scaled += noise

# üìå "–ü–µ—Ä–µ–º—ñ—à—É—î–º–æ" —Ä—ñ–≤–Ω—ñ —Ä–∏–∑–∏–∫—É, —â–æ–± —É–Ω–∏–∫–Ω—É—Ç–∏ –∂–æ—Ä—Å—Ç–∫–æ—ó –ø—Ä–∏–≤‚Äô—è–∑–∫–∏
np.random.shuffle(y.values)

# üìå –†–æ–∑–±–∏–≤–∞—î–º–æ –Ω–∞ —Ç—Ä–µ–Ω—É–≤–∞–ª—å–Ω—ñ —Ç–∞ —Ç–µ—Å—Ç–æ–≤—ñ –¥–∞–Ω—ñ
X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42, stratify=y)

# üìå –í–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É—î–º–æ –º–æ–¥–µ–ª—å –∑ max_depth=5, —â–æ–± –∑–∞–ø–æ–±—ñ–≥—Ç–∏ –ø–µ—Ä–µ–æ–±—É—á–µ–Ω–Ω—é
model = RandomForestClassifier(n_estimators=300, max_depth=6, class_weight="balanced", random_state=42)
model.fit(X_train, y_train)

# üìå –û—Ü—ñ–Ω—é—î–º–æ —Ç–æ—á–Ω—ñ—Å—Ç—å –º–æ–¥–µ–ª—ñ
accuracy = model.score(X_test, y_test)
print(f"üéØ –¢–æ—á–Ω—ñ—Å—Ç—å –º–æ–¥–µ–ª—ñ: {accuracy:.2f}")

# üìå –ó–±–µ—Ä–µ–∂–µ–Ω–Ω—è –º–æ–¥–µ–ª—ñ —Ç–∞ scaler
joblib.dump(model, "backend/health_risk_model.pkl")
joblib.dump(scaler, "backend/scaler.pkl")

print("‚úÖ –ú–æ–¥–µ–ª—å —É—Å–ø—ñ—à–Ω–æ –Ω–∞–≤—á–µ–Ω–∞ —Ç–∞ –∑–±–µ—Ä–µ–∂–µ–Ω–∞!")
